{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: 'Computer Languages (R, Python, Julia, C/C++)'\n",
    "subtitle: Biostat/Biomath M257\n",
    "author: Dr. Hua Zhou @ UCLA\n",
    "date: today\n",
    "format:\n",
    "  html:\n",
    "    theme: cosmo\n",
    "    embed-resources: true\n",
    "    number-sections: true\n",
    "    toc: true\n",
    "    toc-depth: 4\n",
    "    toc-location: left\n",
    "    code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System information (for reproducibility):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.10.2\n",
      "Commit bd47eca2c8a (2024-03-01 10:14 UTC)\n",
      "Build Info:\n",
      "  Official https://julialang.org/ release\n",
      "Platform Info:\n",
      "  OS: macOS (arm64-apple-darwin22.4.0)\n",
      "  CPU: 12 × Apple M2 Max\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-15.0.7 (ORCJIT, apple-m1)\n",
      "Threads: 8 default, 0 interactive, 4 GC (on 8 virtual cores)\n",
      "Environment:\n",
      "  JULIA_NUM_THREADS = 8\n",
      "  JULIA_EDITOR = code\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/github.com/ucla-biostat-257/2024spring/slides/02-langs`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/Documents/github.com/ucla-biostat-257/2024spring/slides/02-langs/Project.toml`\n",
      "  \u001b[90m[6e4b80f9] \u001b[39mBenchmarkTools v1.5.0\n",
      "  \u001b[90m[31c24e10] \u001b[39mDistributions v0.25.107\n",
      "  \u001b[90m[bdcacae8] \u001b[39mLoopVectorization v0.12.166\n",
      "  \u001b[90m[438e738f] \u001b[39mPyCall v1.96.4\n",
      "  \u001b[90m[6f49c342] \u001b[39mRCall v0.14.1\n",
      "  \u001b[90m[8f399da3] \u001b[39mLibdl\n",
      "  \u001b[90m[9a3f8284] \u001b[39mRandom\n",
      "  \u001b[90m[10745b16] \u001b[39mStatistics v1.10.0\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(pwd())\n",
    "Pkg.instantiate()\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we review some popular computer languages commonly used in computational statistics. We want to understand why some languages are faster than others and what are the remedies for the slow languages.\n",
    "\n",
    "## Types of computer languages\n",
    "\n",
    "* **Compiled languages** (low-level languages): C/C++, Fortran, ... \n",
    "  - Directly compiled to machine code that is executed by CPU \n",
    "  - Pros: fast, memory efficient\n",
    "  - Cons: longer development time, hard to debug\n",
    "\n",
    "* **Interpreted language** (high-level languages): R, Matlab, Python, SAS IML, JavaScript, ... \n",
    "  - Interpreted by interpreter\n",
    "  - Pros: fast prototyping\n",
    "  - Cons: excruciatingly slow for loops\n",
    "\n",
    "* Mixed (dynamic) languages: Matlab (JIT), R (`compiler` package), Julia, Cython, JAVA, ...\n",
    "  - Pros and cons: between the compiled and interpreted languages\n",
    "\n",
    "* Script languages: Linux shell scripts, Perl, ...\n",
    "  - Extremely useful for some data preprocessing and manipulation\n",
    "\n",
    "* Database languages: SQL, Hive (Hadoop).  \n",
    "  - Data analysis *never* happens if we do not know how to retrieve data from databases  \n",
    "  \n",
    "  [203B (Introduction to Data Science)](https://ucla-biostat-203b.github.io/2024winter/schedule/schedule-lec1.html) covers some basics on scripting and database.\n",
    "\n",
    "## How high-level languages work?\n",
    "\n",
    "Comics: [The Life of a Bytecode Language](https://betterprogramming.pub/the-life-of-a-bytecode-language-fca666928e7b)\n",
    "\n",
    "- Typical execution of a high-level language such as R, Python, and Matlab.\n",
    "\n",
    "<img src=\"./r-bytecode.png\" align=\"center\" width=\"400\"/>\n",
    "\n",
    "- To improve efficiency of interpreted languages such as R or Matlab, conventional wisdom is to avoid loops as much as possible. Aka, **vectorize code**\n",
    "> The only loop you are allowed to have is that for an iterative algorithm.\n",
    "\n",
    "- When looping is unavoidable, need to code in C, C++, or Fortran. This creates the notorious **two language problem**  \n",
    "Success stories: the popular `glmnet` package in R is coded in Fortran; `tidyverse` and `data.table` packages use a lot RCpp/C++.\n",
    "\n",
    "<img src=\"./two_language_problem.jpg\" align=\"center\" width=\"600\"/>\n",
    "\n",
    "- High-level languages have made many efforts to bring themselves closer to the performance of low-level languages such as C, C++, or Fortran, with a variety levels of success.   \n",
    "    - Matlab has employed JIT (just-in-time compilation) technology since 2002.  \n",
    "    - Since R 3.4.0 (Apr 2017), the JIT bytecode compiler is enabled by default at its level 3.   \n",
    "    - Cython is a compiler system based on Python.  \n",
    "\n",
    "- Modern languages such as Julia tries to solve the two language problem. That is to achieve efficiency without vectorizing code.\n",
    "\n",
    "- Julia execution.\n",
    "\n",
    "<img src=\"./julia_compile.png\" align=\"center\" width=\"400\"/>\n",
    "\n",
    "<img src=\"./julia_introspect.png\" align=\"center\" width=\"400\"/>\n",
    "\n",
    "## Gibbs sampler example by Doug Bates\n",
    "\n",
    "- Doug Bates (member of R-Core, author of popular R packages `Matrix`, `lme4`, `RcppEigen`, etc)\n",
    "    \n",
    "    > As some of you may know, I have had a (rather late) mid-life crisis and run off with another language called Julia.   \n",
    "    >\n",
    "    > -- <cite>Doug Bates (on the `knitr` Google Group)</cite>\n",
    "\n",
    "- An example from Dr. Doug Bates's slides [Julia for R Programmers](http://www.stat.wisc.edu/~bates/JuliaForRProgrammers.pdf).\n",
    "\n",
    "- The task is to create a Gibbs sampler for the density  \n",
    "$$\n",
    "f(x, y) = k x^2 \\exp(- x y^2 - y^2 + 2y - 4x), \\quad x > 0\n",
    "$$\n",
    "using the conditional distributions\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "  X | Y &\\sim& \\Gamma \\left( 3, \\frac{1}{y^2 + 4} \\right) \\\\\n",
    "  Y | X &\\sim& N \\left(\\frac{1}{1+x}, \\frac{1}{2(1+x)} \\right).\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "* R solution. The `RCall.jl` package allows us to execute R code without leaving the `Julia` environment. We first define an R function `Rgibbs()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{VecSxp}\n",
       "R version 4.3.2 (2023-10-31)\n",
       "Platform: aarch64-apple-darwin20 (64-bit)\n",
       "Running under: macOS Sonoma 14.4\n",
       "\n",
       "Matrix products: default\n",
       "BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib \n",
       "LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n",
       "\n",
       "locale:\n",
       "[1] C\n",
       "\n",
       "time zone: America/Los_Angeles\n",
       "tzcode source: internal\n",
       "\n",
       "attached base packages:\n",
       "[1] stats     graphics  grDevices utils     datasets  methods   base     \n",
       "\n",
       "loaded via a namespace (and not attached):\n",
       "[1] compiler_4.3.2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using RCall\n",
    "\n",
    "# show R information\n",
    "R\"\"\"\n",
    "sessionInfo()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{ClosSxp}\n",
       "function (N, thin) \n",
       "{\n",
       "    mat <- matrix(0, nrow = N, ncol = 2)\n",
       "    x <- y <- 0\n",
       "    for (i in 1:N) {\n",
       "        for (j in 1:thin) {\n",
       "            x <- rgamma(1, 3, y * y + 4)\n",
       "            y <- rnorm(1, 1/(x + 1), 1/sqrt(2 * (x + 1)))\n",
       "        }\n",
       "        mat[i, ] <- c(x, y)\n",
       "    }\n",
       "    mat\n",
       "}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define a function for Gibbs sampling\n",
    "\n",
    "R\"\"\"\n",
    "library(Matrix)\n",
    "\n",
    "Rgibbs <- function(N, thin) {\n",
    "  mat <- matrix(0, nrow=N, ncol=2)\n",
    "  x <- y <- 0\n",
    "  for (i in 1:N) {\n",
    "    for (j in 1:thin) {\n",
    "      x <- rgamma(1, 3, y * y + 4) # 3rd arg is rate\n",
    "      y <- rnorm(1, 1 / (x + 1), 1 / sqrt(2 * (x + 1)))\n",
    "    }\n",
    "    mat[i,] <- c(x, y)\n",
    "  }\n",
    "  mat\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a sample of size 10,000 with a thinning of 500. How long does it take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{RealSxp}\n",
       "   user  system elapsed \n",
       " 10.941   0.727  11.934 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "system.time(Rgibbs(10000, 500))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is a Julia function for the same Gibbs sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jgibbs (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Distributions\n",
    "\n",
    "function jgibbs(N, thin)\n",
    "    mat = zeros(N, 2)\n",
    "    x = y = 0.0\n",
    "    for i in 1:N\n",
    "        for j in 1:thin\n",
    "            x = rand(Gamma(3, 1 / (y * y + 4)))\n",
    "            y = rand(Normal(1 / (x + 1), 1 / sqrt(2(x + 1))))\n",
    "        end\n",
    "        mat[i, 1] = x\n",
    "        mat[i, 2] = y\n",
    "    end\n",
    "    mat\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the same number of samples. How long does it take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.112395084"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jgibbs(100, 5); # warm-up\n",
    "@elapsed jgibbs(10000, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see 40-80 fold speed up of `Julia` over `R` on this example, **with similar coding effort**!\n",
    "\n",
    "## Comparing C, C++, R, Python, and Julia\n",
    "\n",
    "To better understand how these languages work, we consider a simple task: summing a vector.\n",
    "\n",
    "Let's first generate data: 1 million double precision numbers from uniform [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500156.3977288406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Random\n",
    "\n",
    "Random.seed!(257) # seed\n",
    "x = rand(1_000_000) # 1 million random numbers in [0, 1)\n",
    "sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this class, we extensively use package `BenchmarkTools.jl` for robust benchmarking. It's the analog of the `microbenchmark` or `bench` package in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C\n",
    "\n",
    "We would use the low-level C code as the baseline for copmarison. In Julia, we can easily run compiled C code using the `ccall` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clang: warning: argument unused during compilation: '-msse3' [-Wunused-command-line-argument]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "c_sum (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Libdl\n",
    "\n",
    "C_code = \"\"\"\n",
    "#include <stddef.h>\n",
    "\n",
    "double c_sum(size_t n, double *X) {\n",
    "    double s = 0.0;\n",
    "    for (size_t i = 0; i < n; ++i) {\n",
    "        s += X[i];\n",
    "    }\n",
    "    return s;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "const Clib = tempname()   # make a temporary file\n",
    "\n",
    "# compile to a shared library by piping C_code to gcc\n",
    "# (works only if you have gcc installed):\n",
    "open(`gcc -std=c99 -fPIC -O3 -msse3 -xc -shared -o $(Clib * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code) \n",
    "end\n",
    "\n",
    "# define a Julia function that calls the C function:\n",
    "c_sum(X :: Array{Float64}) = ccall((\"c_sum\", Clib), Float64, (Csize_t, Ptr{Float64}), length(X), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500156.39772885485"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make sure it gives same answer\n",
    "c_sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 5999 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m811.625 μs\u001b[22m\u001b[39m … \u001b[35m993.000 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m823.958 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m829.585 μs\u001b[22m\u001b[39m ± \u001b[32m 20.845 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m█\u001b[39m▂\u001b[39m▆\u001b[39m▃\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[34m▄\u001b[39m\u001b[39m▄\u001b[39m▄\u001b[32m▄\u001b[39m\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▇\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m \u001b[39m█\n",
       "  812 μs\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m        911 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dollar sign to interpolate array x into local scope for benchmarking\n",
    "bm = @benchmark c_sum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.823958"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a dictionary to store median runtime (in milliseconds)\n",
    "benchmark_result = Dict() \n",
    "\n",
    "# store median runtime (in milliseconds)\n",
    "benchmark_result[\"C\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R, buildin sum\n",
    "\n",
    "Next we compare to the build in `sum` function in R, which is implemented using C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: RCall.jl: -- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\n",
      "│ v dplyr     1.1.3     v readr     2.1.4\n",
      "│ v forcats   1.0.0     v stringr   1.5.0\n",
      "│ v ggplot2   3.4.4     v tibble    3.2.1\n",
      "│ v lubridate 1.9.2     v tidyr     1.3.0\n",
      "│ v purrr     1.0.2     \n",
      "│ -- Conflicts ------------------------------------------ tidyverse_conflicts() --\n",
      "│ x tidyr::expand() masks Matrix::expand()\n",
      "│ x dplyr::filter() masks stats::filter()\n",
      "│ x dplyr::lag()    masks stats::lag()\n",
      "│ x tidyr::pack()   masks Matrix::pack()\n",
      "│ x tidyr::unpack() masks Matrix::unpack()\n",
      "│ i Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n",
      "└ @ RCall /Users/huazhou/.julia/packages/RCall/dDAVd/src/io.jl:172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 1 x 13\n",
      "  expression      min   median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc\n",
      "  <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> <int> <dbl>\n",
      "1 sum(y)       1.33ms   1.37ms      720.        0B        0   360     0\n",
      "  total_time result    memory             time             gc                \n",
      "    <bch:tm> <list>    <list>             <list>           <list>            \n",
      "1      500ms <dbl [1]> <Rprofmem [0 x 3]> <bench_tm [360]> <tibble [360 x 3]>\n"
     ]
    }
   ],
   "source": [
    "R\"\"\"\n",
    "library(bench)\n",
    "library(tidyverse)\n",
    "\n",
    "# interpolate x into R workspace\n",
    "y <- $x\n",
    "rbm_builtin <- bench::mark(sum(y)) %>%\n",
    "  print(width = Inf)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3731925282627344"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store median runtime (in milliseconds)\n",
    "@rget rbm_builtin # dataframe\n",
    "benchmark_result[\"R builtin\"] = median(rbm_builtin[!, :median]) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R, handwritten loop\n",
    "\n",
    "Handwritten loop in R is much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 1 x 13\n",
      "  expression      min   median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc\n",
      "  <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> <int> <dbl>\n",
      "1 sum_r(y)     7.08ms    7.6ms      132.    13.1KB        0    66     0\n",
      "  total_time result    memory              time            gc               \n",
      "    <bch:tm> <list>    <list>              <list>          <list>           \n",
      "1      501ms <dbl [1]> <Rprofmem [42 x 3]> <bench_tm [66]> <tibble [66 x 3]>\n"
     ]
    }
   ],
   "source": [
    "R\"\"\"\n",
    "sum_r <- function(x) {\n",
    "  s <- 0\n",
    "  for (xi in x) {\n",
    "    s <- s + xi\n",
    "  }\n",
    "  s\n",
    "}\n",
    "library(bench)\n",
    "y <- $x\n",
    "rbm_loop <- bench::mark(sum_r(y)) %>%\n",
    "  print(width = Inf)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.598653028253466"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store median runtime (in milliseconds)\n",
    "@rget rbm_loop # dataframe\n",
    "benchmark_result[\"R loop\"] = median(rbm_loop[!, :median]) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R, Rcpp\n",
    "\n",
    "Rcpp package provides an easy way to incorporate C++ code in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{ClosSxp}\n",
       "function (x) \n",
       ".Call(<pointer: 0x3491c08c0>, x)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "library(Rcpp)\n",
    "\n",
    "cppFunction('double rcpp_sum(NumericVector x) {\n",
    "  int n = x.size();\n",
    "  double total = 0;\n",
    "  for(int i = 0; i < n; ++i) {\n",
    "    total += x[i];\n",
    "  }\n",
    "  return total;\n",
    "}')\n",
    "\n",
    "rcpp_sum\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 1 x 13\n",
      "  expression       min   median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc\n",
      "  <bch:expr>  <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> <int> <dbl>\n",
      "1 rcpp_sum(y)    800us    852us     1154.    2.49KB        0   577     0\n",
      "  total_time result    memory             time             gc                \n",
      "    <bch:tm> <list>    <list>             <list>           <list>            \n",
      "1      500ms <dbl [1]> <Rprofmem [1 x 3]> <bench_tm [577]> <tibble [577 x 3]>\n"
     ]
    }
   ],
   "source": [
    "R\"\"\"\n",
    "rbm_rcpp <- bench::mark(rcpp_sum(y)) %>%\n",
    "  print(width = Inf)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8523900178261101"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store median runtime (in milliseconds)\n",
    "@rget rbm_rcpp # dataframe\n",
    "benchmark_result[\"R Rcpp\"] = median(rbm_rcpp[!, :median]) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python, builtin sum\n",
    "\n",
    "Built in function `sum` in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v\"3.10.12\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using PyCall\n",
    "\n",
    "PyCall.pyversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 129 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m37.617 ms\u001b[22m\u001b[39m … \u001b[35m 39.755 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m38.883 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m38.813 ms\u001b[22m\u001b[39m ± \u001b[32m447.683 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\u001b[39m \u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▄\u001b[39m \u001b[39m \u001b[39m \u001b[39m▆\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m▂\u001b[39m\u001b[39m▆\u001b[34m▂\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m \u001b[39m▄\u001b[39m█\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▄\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▆\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▄\u001b[39m▆\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m█\u001b[39m▄\u001b[39m█\u001b[39m▄\u001b[39m▁\u001b[39m▄\u001b[39m█\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▆\u001b[39m▄\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m▄\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[32m█\u001b[39m\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▄\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▁\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▄\u001b[39m \u001b[39m▄\n",
       "  37.6 ms\u001b[90m         Histogram: frequency by time\u001b[39m         39.7 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m240 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m6\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the Python built-in \"sum\" function:\n",
    "pysum = pybuiltin(\"sum\")\n",
    "bm = @benchmark $pysum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.883459"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store median runtime (in miliseconds)\n",
    "benchmark_result[\"Python builtin\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python, handwritten loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 105 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m45.974 ms\u001b[22m\u001b[39m … \u001b[35m 48.898 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m47.732 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m47.631 ms\u001b[22m\u001b[39m ± \u001b[32m545.860 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[32m▄\u001b[39m\u001b[39m \u001b[34m \u001b[39m\u001b[39m▁\u001b[39m \u001b[39m▂\u001b[39m \u001b[39m█\u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m▃\u001b[39m▅\u001b[39m▃\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▁\u001b[39m▆\u001b[39m▅\u001b[39m▃\u001b[39m▁\u001b[39m▆\u001b[39m▃\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m▆\u001b[34m▆\u001b[39m\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▅\u001b[39m█\u001b[39m▅\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m \u001b[39m▃\n",
       "  46 ms\u001b[90m           Histogram: frequency by time\u001b[39m         48.8 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m240 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m6\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "py\"\"\"\n",
    "def py_sum(A):\n",
    "    s = 0.0\n",
    "    for a in A:\n",
    "        s += a\n",
    "    return s\n",
    "\"\"\"\n",
    "\n",
    "sum_py = py\"py_sum\"\n",
    "\n",
    "bm = @benchmark $sum_py($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.732083"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store median runtime (in miliseconds)\n",
    "benchmark_result[\"Python loop\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python, numpy\n",
    "\n",
    "Numpy is the high-performance scientific computing library for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <function sum at 0x34a36ea30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bring in sum function from Numpy \n",
    "numpy_sum = pyimport(\"numpy\").\"sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m160.708 μs\u001b[22m\u001b[39m … \u001b[35m279.334 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m173.750 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m176.551 μs\u001b[22m\u001b[39m ± \u001b[32m  5.542 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▇\u001b[39m█\u001b[34m▅\u001b[39m\u001b[39m▃\u001b[39m▁\u001b[39m \u001b[32m▅\u001b[39m\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m▄\u001b[39m▄\u001b[39m▁\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m \u001b[39m█\n",
       "  161 μs\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m        197 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m240 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m6\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bm = @benchmark $numpy_sum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store median runtime (in miliseconds)\n",
    "benchmark_result[\"Python numpy\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy performance is on a par with Julia build-in sum function. Both are about 3 times faster than C, possibly because of usage of [SIMD](https://en.wikipedia.org/wiki/SIMD).\n",
    "\n",
    "### Julia, builtin sum\n",
    "\n",
    "`@time`, `@elapsed`, `@allocated` macros in Julia report run times and memory allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000184 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500156.3977288406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@time sum(x) # no compilation time after first run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more robust benchmarking, we use BenchmarkTools.jl package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m159.833 μs\u001b[22m\u001b[39m … \u001b[35m228.250 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m160.750 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m164.049 μs\u001b[22m\u001b[39m ± \u001b[32m  6.280 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m▁\u001b[39m█\u001b[34m▅\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▄\u001b[32m▃\u001b[39m\u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\n",
       "  \u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▃\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▃\u001b[39m▃\u001b[39m \u001b[39m█\n",
       "  160 μs\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m        188 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bm = @benchmark sum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16075"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "benchmark_result[\"Julia builtin\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Julia, handwritten loop\n",
    "\n",
    "Let's also write a loop and benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 5969 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m811.625 μs\u001b[22m\u001b[39m … \u001b[35m 1.042 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m829.500 μs              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m836.934 μs\u001b[22m\u001b[39m ± \u001b[32m26.608 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m█\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[34m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m█\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▅\u001b[39m▇\u001b[34m▅\u001b[39m\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[32m▄\u001b[39m\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▂\n",
       "  812 μs\u001b[90m          Histogram: frequency by time\u001b[39m          931 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function jl_sum(A)\n",
    "    s = zero(eltype(A))\n",
    "    for a in A\n",
    "        s += a\n",
    "    end\n",
    "    s\n",
    "end\n",
    "\n",
    "bm = @benchmark jl_sum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8295"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "benchmark_result[\"Julia loop\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: annotate the loop by [`@simd`](https://docs.julialang.org/en/v1/manual/performance-tips/#man-performance-annotations-1) or `LoopVectorization.@turbo` and benchmark again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m81.625 μs\u001b[22m\u001b[39m … \u001b[35m167.416 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m89.750 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m90.455 μs\u001b[22m\u001b[39m ± \u001b[32m  4.697 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m▃\u001b[39m▄\u001b[39m▅\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▅\u001b[39m▇\u001b[34m█\u001b[39m\u001b[39m▃\u001b[32m▁\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\u001b[39m▄\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m▅\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m \u001b[39m█\n",
       "  81.6 μs\u001b[90m       \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m       106 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LoopVectorization\n",
    "\n",
    "function jl_sum_turbo(A)\n",
    "    s = zero(eltype(A))\n",
    "    @turbo for i in eachindex(A)\n",
    "      s += A[i]\n",
    "    end\n",
    "    s\n",
    "end\n",
    "\n",
    "bm = @benchmark jl_sum_turbo($x)\n",
    "bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08975"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "benchmark_result[\"Julia turbo\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@tturbo` macro turns on multi-threading. Note for this to function, Julia needs to be started with multi-threading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m42.791 μs\u001b[22m\u001b[39m … \u001b[35m138.125 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m45.500 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m46.621 μs\u001b[22m\u001b[39m ± \u001b[32m  3.054 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▄\u001b[39m█\u001b[34m▂\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[32m▁\u001b[39m\u001b[39m▂\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\n",
       "  \u001b[39m▇\u001b[39m▇\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▅\u001b[39m▃\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▄\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m \u001b[39m█\n",
       "  42.8 μs\u001b[90m       \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      58.2 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function jl_sum_tturbo(A)\n",
    "    s = zero(eltype(A))\n",
    "    @tturbo for i in eachindex(A)\n",
    "      s += A[i]\n",
    "    end\n",
    "    s\n",
    "end\n",
    "\n",
    "bm = @benchmark jl_sum_tturbo($x)\n",
    "bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0455"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "benchmark_result[\"Julia tturbo\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Vector{Pair{Any, Any}}:\n",
       "   \"Julia tturbo\" => 0.0455\n",
       "    \"Julia turbo\" => 0.08975\n",
       "  \"Julia builtin\" => 0.16075\n",
       "   \"Python numpy\" => 0.17375\n",
       "              \"C\" => 0.823958\n",
       "     \"Julia loop\" => 0.8295\n",
       "         \"R Rcpp\" => 0.8523900178261101\n",
       "      \"R builtin\" => 1.3731925282627344\n",
       "         \"R loop\" => 7.598653028253466\n",
       " \"Python builtin\" => 38.883459\n",
       "    \"Python loop\" => 47.732083"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sort(collect(benchmark_result), by = x -> x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `C`, `R builtin` are the baseline C performance (gold standard).\n",
    "\n",
    "* `Python builtin` and `Python loop` are >50 fold slower than C because the loop is interpreted.\n",
    "\n",
    "* `R loop` is about 10 times slower than C and indicates the performance of JIT bytecode generated by its `compiler` package (turned on by default since R v3.4.0 (Apr 2017)). \n",
    "\n",
    "* `Julia loop` is close to C performance, because Julia code is JIT compiled.\n",
    "\n",
    "* `Julia builtin`, `Python numpy`, and `Julia turbo` are 4-5 fold faster than C because of SIMD.\n",
    "\n",
    "* `@turbo` (SIMD) and `@tturbo` (multithreading+SIMD), offered by the LoopVectorization.jl package. yields the top performance on this machine.\n",
    "\n",
    "## Take home message for computational scientists\n",
    "\n",
    "- High-level language (R, Python, Matlab) programmers should be familiar with existing high-performance packages.  Don't reinvent wheels.  \n",
    "    - R: RcppEigen, tidyverse, ...   \n",
    "    - Python: numpy, scipy, ...  \n",
    "\n",
    "- In most research projects, looping is unavoidable. Then we need to use a low-level language.  \n",
    "    - R: Rcpp, ...  \n",
    "    - Python: Cython, ...  \n",
    "    \n",
    "- In this course, we use Julia, which circumvents the two language problem. So we can spend more time on algorithms, not on juggling $\\ge 2$ languages.  "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,qmd"
  },
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "511.7391357421875px",
    "width": "251.7391357421875px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "640.4212036132812px",
    "left": "0px",
    "right": "1210.6114501953125px",
    "top": "109.57880401611328px",
    "width": "211.99728393554688px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
