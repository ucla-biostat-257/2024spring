{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Optimization in Julia\n",
    "subtitle: Biostat/Biomath M257\n",
    "author: Dr. Hua Zhou @ UCLA\n",
    "date: today\n",
    "format:\n",
    "  html:\n",
    "    theme: cosmo\n",
    "    embed-resources: true\n",
    "    number-sections: true\n",
    "    toc: true\n",
    "    toc-depth: 4\n",
    "    toc-location: left\n",
    "    code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System information (for reproducibility):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Pkg\n",
    "\n",
    "Pkg.activate(pwd())\n",
    "Pkg.instantiate()\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization in Julia\n",
    "\n",
    "This lecture gives an overview of some optimization tools in Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flowchart\n",
    "\n",
    "* Statisticians do optimizations in daily life: maximum likelihood estimation, machine learning, ...\n",
    "\n",
    "* Category of optimization problems:\n",
    "\n",
    "    1. Problems with analytical solutions: least squares, principle component analysis, canonical correlation analysis, ...\n",
    "    \n",
    "    2. Problems subject to Disciplined Convex Programming (DCP): linear programming (LP), quadratic programming (QP), second-order cone programming (SOCP), semidefinite programming (SDP), and geometric programming (GP).\n",
    "    \n",
    "    3. Nonlinear programming (NLP): Newton type algorithms, Fisher scoring algorithm, EM algorithm, MM algorithms. \n",
    "    \n",
    "    4. Large scale optimization: ADMM, SGD, ...\n",
    "    \n",
    "![Flowchart](./optimization_flowchart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling tools and solvers\n",
    "\n",
    "Getting familiar with **good** optimization softwares broadens the scope and scale of problems we are able to solve in statistics. Following table lists some of the best optimization softwares. \n",
    "\n",
    "\n",
    "|           |   | LP | MILP | SOCP |     MISOCP     | SDP | GP | NLP | MINLP |   | R | Matlab | Julia | Python |   | Cost |  \n",
    "|:---------:|:-:|:--:|:----:|:----:|:--------------:|:---:|:--:|:---:|:-----:|:-:|:-:|:------:|:-----:|:------:|:-:|:----:|  \n",
    "|   **modeling tools**   |   |    |      |      |                |     |    |     |       |   |   |        |       |        |   |      |  \n",
    "|    cvx    |   |  x |   x  |   x  |        x       |  x  |  x |     |       |   | x |    x   |       |    x   |   |   A  |  \n",
    "| Convex.jl |   |  x |   x  |   x  |        x       |  x  |    |     |       |   |   |        |   x   |        |   |   O  |  \n",
    "|  Optimization.jl  |   |  x |   x  |   x  |        x       |     |    |  x  |   x   |   |   |        |   x   |        |   |   O  |  \n",
    "|  JuMP.jl  |   |  x |   x  |   x  |        x       |     |    |  x  |   x   |   |   |        |   x   |        |   |   O  |  \n",
    "| MathOptInterface.jl |   |  x |   x  |   x  |        x       |     |    |  x  |   x   |   |   |        |   x   |        |   |   O  |  \n",
    "|   **convex solvers** |   |    |      |      |                |     |    |     |       |   |   |        |       |        |   |      |  \n",
    "|   Mosek   |   |  x |   x  |   x  |        x       |  x  |  x |  x  |       |   | x |    x   |   x   |    x   |   |   A  |  \n",
    "|   Gurobi  |   |  x |   x  |   x  |        x       |     |    |     |       |   | x |    x   |   x   |    x   |   |   A  |  \n",
    "|   CPLEX   |   |  x |   x  |   x  |        x       |     |    |     |       |   | x |    x   |   x   |    x   |   |   A  |  \n",
    "|    SCS    |   |  x |      |   x  |                |  x  |    |     |       |   |   |    x   |   x   |    x   |   |   O  |  \n",
    "|    COSMO.jl    |  |  x |  |  x |              |  x  |    |     |       |   |   |     |   x   |     |   |   O  |  \n",
    "|    Hypatia.jl (more cones)   |  |  x |  |  x |              |  x  |    |     |       |   |   |     |   x   |     |   |   O  |   \n",
    "|   **NLP solvers**  |   |    |      |      |                |     |    |     |       |   |   |        |       |        |   |      |  \n",
    "|   NLopt   |   |  x |      |      |                |     |    |  x  |       |   | x |    x   |   x   |    x   |   |   O  |  \n",
    "|   Ipopt   |   |  x |      |      |                |     |    |  x  |       |   | x |    x   |   x   |    x   |   |   O  |  \n",
    "|   KNITRO  |   |  x |   x  |      |                |     |    |  x  |   x   |   | x |    x   |   x   |    x   |   |   $  |  \n",
    "\n",
    "    O: open source, A: free academic license, $: commercial\n",
    "\n",
    "* For more extended list of solvers, see [here](https://jump.dev/JuMP.jl/stable/installation/#Supported-solvers).\n",
    "\n",
    "* Difference between **modeling tool** and **solvers**\n",
    "\n",
    "    - **Modeling tools** such as cvx (for Matlab) and Convex.jl (Julia analog of cvx) implement the disciplined convex programming (DCP) paradigm proposed by Grant and Boyd (2008) <http://stanford.edu/~boyd/papers/disc_cvx_prog.html>. DCP prescribes a set of simple rules from which users can construct convex optimization problems easily.\n",
    "    \n",
    "    - **Solvers** (Mosek, Gurobi, Cplex, SCS, COSMO, Hypatia, ...) are concrete software implementation of optimization algorithms. My favorite ones are: Mosek/Gurobi/SCS for DCP and Ipopt/NLopt for nonlinear programming. Mosek and Gurobi are commercial software but free for academic use. SCS/Ipopt/NLopt are open source.  \n",
    "    \n",
    "    - Modeling tools usually have the capability to use a variety of solvers. But modeling tools are solver agnostic so users do not have to worry about specific solver interface.\n",
    "    \n",
    "* If you want to install the commercial solvers Gurobi or Mosek, instructions are below:\n",
    "    - Gurobi: 1. Download Gurobi at [link](https://www.gurobi.com/downloads/gurobi-software/). 2. Register an account and request free academic license at [link](https://portal.gurobi.com/iam/register/). 3. Run `grbgetkey XXXXXXXXX` command on terminal as suggested. It'll retrieve a license file and put it under a specified folder, e.g., `/Users/huazhou/Documents/Gurobi/gurobi.lic`. 4. Set up the environmental variables. On my machine, I put following two lines in the `~/.julia/config/startup.jl` file: `ENV[\"GUROBI_HOME\"] = \"/Library/gurobi1101/macos_universal2\"` and `ENV[\"GRB_LICENSE_FILE\"] = \"/Users/huazhou/Documents/Gurobi/gurobi.lic\"`.  \n",
    "    - Mosek: 1. Request free academic license at [link](https://www.mosek.com/products/academic-licenses/). The license file will be sent to your edu email within minutes. Check Spam folder if necessary. 2. Put the license file at the default location `~/mosek/`.\n",
    "    - Install Julia packages Convex.jl, SCS.jl, Gurobi.jl, Mosek.jl, MathProgBase.jl, NLopt.jl, Ipopt.jl, which are open source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCP Using Convex.jl\n",
    "\n",
    "Standard convex problem classes like LP (linear programming), QP (quadratic programming), SOCP (second-order cone programming), SDP (semidefinite programming), and GP (geometric programming), are becoming a **technology**.\n",
    "\n",
    "![DCP Hierarchy](./convex-hierarchy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: microbiome regression analysis\n",
    "\n",
    "We illustrate optimization tools in Julia using microbiome analysis as an example.\n",
    "\n",
    "16S microbiome sequencing techonology generates sequence counts of various organisms (OTUs, operational taxonomic units) in samples. \n",
    "\n",
    "![Microbiome Data](./microbiome_data.png)\n",
    "\n",
    "For statistical analysis, counts are normalized into **proportions** for each sample, resulting in a covariate matrix $\\mathbf{X}$ with all rows summing to 1. For identifiability, we need to add a sum-to-zero constraint to the regression cofficients. In other words, we need to solve a **constrained least squares problem**  \n",
    "$$\n",
    "    \\text{minimize} \\frac{1}{2} \\|\\mathbf{y} - \\mathbf{X} \\beta\\|_2^2\n",
    "$$\n",
    "subject to the constraint $\\sum_{j=1}^p \\beta_j = 0$. For simplicity we ignore intercept and non-OTU covariates in this presentation.\n",
    "\n",
    "Let's first generate an artifical data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Random, LinearAlgebra, SparseArrays\n",
    "\n",
    "Random.seed!(257) # seed\n",
    "\n",
    "n, p = 100, 50\n",
    "X = rand(n, p)\n",
    "# scale each row of X sum to 1\n",
    "lmul!(Diagonal(1 ./ vec(sum(X, dims=2))), X)\n",
    "# true β is a sparse vector with about 10% non-zero entries\n",
    "β = sprandn(p, 0.1) \n",
    "y = X * β + randn(n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum-to-zero regression\n",
    "\n",
    "The sum-to-zero contrained least squares is a standard quadratic programming (QP) problem so should be solved easily by any QP solver.\n",
    "\n",
    "#### Modeling using Convex.jl\n",
    "\n",
    "We use the Convex.jl package to model this QP problem. For a complete list of operations supported by Convex.jl, see <https://jump.dev/Convex.jl/stable/operations/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Convex\n",
    "\n",
    "β̂cls = Variable(size(X, 2))\n",
    "problem = minimize(0.5sumsquares(y - X * β̂cls)) # objective\n",
    "problem.constraints += sum(β̂cls) == 0; # constraint\n",
    "problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mosek\n",
    "\n",
    "We first use the Mosek solver to solve this QP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using MosekTools, MathOptInterface\n",
    "const MOI = MathOptInterface\n",
    "\n",
    "solver = Mosek.Optimizer()\n",
    "MOI.set(solver, MOI.RawOptimizerAttribute(\"LOG\"), 1)\n",
    "\n",
    "@time solve!(problem, solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the status, optimal value, and minimizer of the problem\n",
    "problem.status, problem.optval, β̂cls.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check constraint satisfication\n",
    "sum(β̂cls.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gurobi\n",
    "\n",
    "Switch to Gurobi solver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Gurobi\n",
    "\n",
    "solver = Gurobi.Optimizer()\n",
    "MOI.set(solver, MOI.RawOptimizerAttribute(\"OutputFlag\"), 1)\n",
    "\n",
    "@time solve!(problem, solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the status, optimal value, and minimizer of the problem\n",
    "problem.status, problem.optval, β̂cls.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check constraint satisfication\n",
    "sum(β̂cls.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COSMO\n",
    "\n",
    "Switch to [COSMO solver](https://github.com/oxfordcontrol/COSMO.jl) (pure Julia implementation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use COSMO solver\n",
    "using COSMO\n",
    "\n",
    "solver = COSMO.Optimizer()\n",
    "MOI.set(solver, MOI.RawOptimizerAttribute(\"max_iter\"), 5000)\n",
    "\n",
    "@time solve!(problem, solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the status, optimal value, and minimizer of the problem\n",
    "problem.status, problem.optval, β̂cls.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see COSMO have a looser criterion for constraint satisfication, resulting a lower objective value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(β̂cls.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SCS\n",
    "\n",
    "Switch to the open source [SCS solver](https://github.com/jump-dev/SCS.jl):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use SCS solver\n",
    "using SCS\n",
    "\n",
    "solver = SCS.Optimizer()\n",
    "MOI.set(solver, MOI.RawOptimizerAttribute(\"verbose\"), 1)\n",
    "\n",
    "@time solve!(problem, solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the status, optimal value, and minimizer of the problem\n",
    "problem.status, problem.optval, β̂cls.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check constraint satisfication\n",
    "sum(β̂cls.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypatia\n",
    "\n",
    "Switch to the open source [Hypatia](https://github.com/jump-dev/Hypatia.jl) (pure Julia) solver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use Hypatia solver\n",
    "using Hypatia\n",
    "\n",
    "solver = Hypatia.Optimizer()\n",
    "MOI.set(solver, MOI.RawOptimizerAttribute(\"verbose\"), 1)\n",
    "\n",
    "@time solve!(problem, solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the status, optimal value, and minimizer of the problem\n",
    "problem.status, problem.optval, β̂cls.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check constraint satisfication\n",
    "sum(β̂cls.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum-to-zero lasso\n",
    "\n",
    "Suppose we want to know which organisms (OTU) are associated with the response. We can answer this question using a sum-to-zero contrained lasso\n",
    "$$\n",
    "    \\text{minimize} \\frac 12 \\|\\mathbf{y} - \\mathbf{X} \\beta\\|_2^2 + \\lambda \\|\\beta\\|_1\n",
    "$$\n",
    "subject to the constraint $\\sum_{j=1}^p \\beta_j = 0$. Varying $\\lambda$ from small to large values will generate a solution path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Convex\n",
    "\n",
    "# # Use Mosek solver\n",
    "# using Mosek\n",
    "# solver = Mosek.Optimizer()\n",
    "# MOI.set(solver, MOI.RawOptimizerAttribute(\"LOG\"), 0)\n",
    "\n",
    "# # Use Gurobi solver\n",
    "# using Gurobi\n",
    "# solver = Gurobi.Optimizer(OutputFlag=0)\n",
    "\n",
    "# Use Cplex solver\n",
    "# using CPLEX\n",
    "# solver = CplexSolver(CPXPARAM_ScreenOutput=0)\n",
    "\n",
    "# # Use SCS solver\n",
    "# using SCS\n",
    "# solver = SCS.Optimizer(verbose=0)\n",
    "\n",
    "# Use Hypatia solver\n",
    "using Hypatia\n",
    "solver = Hypatia.Optimizer()\n",
    "\n",
    "# solve at a grid of λ\n",
    "λgrid = 0:0.01:0.35\n",
    "\n",
    "# holder for solution path\n",
    "β̂path = zeros(length(λgrid), size(X, 2)) # each row is β̂ at a λ\n",
    "# optimization variable\n",
    "β̂classo = Variable(size(X, 2))\n",
    "# obtain solution path using warm start\n",
    "@time for i in 1:length(λgrid)\n",
    "    λ = λgrid[i]\n",
    "    # define optimization problem\n",
    "    # objective\n",
    "    problem = minimize(0.5sumsquares(y - X * β̂classo) + λ * sum(abs, β̂classo))\n",
    "    # constraint\n",
    "    problem.constraints += sum(β̂classo) == 0 # constraint\n",
    "    solver = Mosek.Optimizer()\n",
    "    MOI.set(solver, MOI.RawOptimizerAttribute(\"LOG\"), 0)\n",
    "    solve!(problem, solver)\n",
    "    β̂path[i, :] = β̂classo.value\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using CairoMakie\n",
    "\n",
    "f = Figure()\n",
    "Axis(\n",
    "    f[1, 1], \n",
    "    title = \"Sum-to-Zero Lasso\",\n",
    "    xlabel = L\"\\lambda\",\n",
    "    ylabel = L\"\\beta_j\"\n",
    ")\n",
    "series!(λgrid, β̂path', color = :glasbey_category10_n256)\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum-to-zero group lasso\n",
    "\n",
    "Suppose we want to do variable selection not at the OTU level, but at the Phylum level. OTUs are clustered into various Phyla. We can answer this question using a sum-to-zero contrained group lasso\n",
    "$$\n",
    "    \\text{minimize} \\frac 12 \\|\\mathbf{y} - \\mathbf{X} \\beta\\|_2^2 + \\lambda \\sum_j \\|\\mathbf{\\beta}_j\\|_2\n",
    "$$\n",
    "subject to the constraint $\\sum_{j=1}^p \\beta_j = 0$, where $\\mathbf{\\beta}_j$ are regression coefficients corresponding to the $j$-th phylum. This is a second-order cone programming (SOCP) problem readily modeled by Convex.jl.\n",
    "\n",
    "Let's assume each 10 contiguous OTUs belong to one Phylum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Use Mosek solver\n",
    "# using MosekTools\n",
    "\n",
    "# # Use Gurobi solver\n",
    "# using Gurobi\n",
    "\n",
    "# # Use Cplex solver\n",
    "# using CPLEX\n",
    "# solver = CplexSolver(CPXPARAM_ScreenOutput=0)\n",
    "\n",
    "# # Use SCS solver\n",
    "# using SCS\n",
    "# solver = SCSSolver(verbose=0)\n",
    "\n",
    "# Use Hypatia solver\n",
    "using Hypatia\n",
    "solver = Hypatia.Optimizer()\n",
    "\n",
    "# solve at a grid of λ\n",
    "λgrid = 0.0:0.005:0.5\n",
    "β̂pathgrp = zeros(length(λgrid), size(X, 2)) # each row is β̂ at a λ\n",
    "β̂classo = Variable(size(X, 2))\n",
    "@time for i in 1:length(λgrid)\n",
    "    λ = λgrid[i]\n",
    "    # loss\n",
    "    obj = 0.5sumsquares(y - X * β̂classo)\n",
    "    # group lasso penalty term\n",
    "    for j in 1:(size(X, 2)/10)\n",
    "        βj = β̂classo[(10(j-1)+1):10j]\n",
    "        obj = obj + λ * norm(βj)\n",
    "    end\n",
    "    problem = minimize(obj)\n",
    "    # constraint\n",
    "    problem.constraints += sum(β̂classo) == 0 # constraint\n",
    "    solver = Mosek.Optimizer()\n",
    "    MOI.set(solver, MOI.RawOptimizerAttribute(\"LOG\"), 0)\n",
    "    solve!(problem, solver)\n",
    "    β̂pathgrp[i, :] = β̂classo.value\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see it took Mosek <2 second to solve this seemingly hard optimization problem at **101** different $\\lambda$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using CairoMakie\n",
    "\n",
    "f = Figure()\n",
    "Axis(\n",
    "    f[1, 1], \n",
    "    title = \"Sum-to-Zero Group Lasso\",\n",
    "    xlabel = L\"\\lambda\",\n",
    "    ylabel = L\"\\beta_j\"\n",
    ")\n",
    "series!(λgrid, β̂pathgrp', color = :glasbey_category10_n256)\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: matrix completion\n",
    "\n",
    "Load the $128 \\times 128$ Lena picture with missing pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using FileIO\n",
    "\n",
    "lena = load(\"lena128missing.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert to real matrices\n",
    "Y = Float64.(lena)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fill out the missin pixels uisng a **matrix completion** technique developed by Candes and Tao\n",
    "$$\n",
    "    \\text{minimize } \\|\\mathbf{X}\\|_*\n",
    "$$\n",
    "$$\n",
    "    \\text{subject to } x_{ij} = y_{ij} \\text{ for all observed entries } (i, j).\n",
    "$$\n",
    "Here $\\|\\mathbf{M}\\|_* = \\sum_i \\sigma_i(\\mathbf{M})$ is the nuclear norm. In words we seek the matrix with minimal nuclear norm that agrees with the observed entries. This is a semidefinite programming (SDP) problem readily modeled by Convex.jl.\n",
    "\n",
    "This example takes longer because of high dimensionality. COSMO.jl seems to be the fastest solver for this problem. Other solvers take excessively long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use COSMO solver\n",
    "using COSMO\n",
    "solver = COSMO.Optimizer()\n",
    "\n",
    "# # Use Hypatia solver\n",
    "# using Hypatia\n",
    "# solver = Hypatia.Optimizer()\n",
    "\n",
    "# Linear indices of obs. entries\n",
    "obsidx = findall(Y[:] .≠ 0.0)\n",
    "# Create optimization variables\n",
    "X = Variable(size(Y))\n",
    "# Set up optmization problem\n",
    "problem = minimize(nuclearnorm(X))\n",
    "problem.constraints += X[obsidx] == Y[obsidx]\n",
    "# Solve the problem by calling solve\n",
    "@time solve!(problem, solver) # fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Images\n",
    "\n",
    "#Gray.(X.value)\n",
    "colorview(Gray, X.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear programming (NLP)\n",
    "\n",
    "We use MLE of Gamma distribution to illustrate some rudiments of nonlinear programming (NLP) in Julia. \n",
    "\n",
    "Let $x_1,\\ldots,x_m$ be a random sample from the gamma density\n",
    "$$\n",
    "f(x) = \\Gamma(\\alpha)^{-1} \\beta^{\\alpha} x^{\\alpha-1} e^{-\\beta x}\n",
    "$$\n",
    "on $(0,\\infty)$. The loglikelihood function is\n",
    "$$\n",
    "    L(\\alpha, \\beta) = m [- \\ln \\Gamma(\\alpha) + \\alpha \\ln \\beta + (\\alpha - 1)\\overline{\\ln x} - \\beta \\bar x],\n",
    "$$\n",
    "where $\\overline{x} = \\frac{1}{m} \\sum_{i=1}^m x_i$ and \n",
    "$\\overline{\\ln x} = \\frac{1}{m} \\sum_{i=1}^m \\ln x_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define NLP optimization problem using Optimization.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions, Optimization, Random, Statistics, SpecialFunctions\n",
    "\n",
    "Random.seed!(257)\n",
    "\n",
    "# θ = (α, β)\n",
    "function gamma_logpdf(x::Vector{<:Real}, θ::Vector{<:Real})\n",
    "    m = length(x)\n",
    "    avg = mean(x)\n",
    "    α, β = θ[1], θ[2]\n",
    "    logavg = sum(log, x) / m\n",
    "    m * (- log(gamma(α)) + α * log(β) + (α - 1) * logavg - β * avg)\n",
    "end\n",
    "\n",
    "# test data\n",
    "x = rand(5)\n",
    "gamma_logpdf(x, [1.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "\n",
    "(n, p) = (1000, 2)\n",
    "(α, β) = 5rand(p)\n",
    "x = rand(Gamma(α, β), n)\n",
    "println(\"True parameter values:\")\n",
    "println(\"α = \", α, \", β = \", β)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [Optimization.jl](https://github.com/SciML/Optimization.jl) to define and solve our NLP problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ForwardDiff, Optimization\n",
    "\n",
    "# loss function and gradient (by auto-diff)\n",
    "loss = (θ, p) -> -gamma_logpdf(x, θ)\n",
    "# more auto-diff choices: https://docs.sciml.ai/Optimization/stable/API/ad/\n",
    "optf = OptimizationFunction(loss, Optimization.AutoForwardDiff())\n",
    "# start point\n",
    "θ₀ = [1.0, 1.0]\n",
    "# optimization problem\n",
    "prob = OptimizationProblem(optf, θ₀, lb = [0.0, 0.0], ub = [Inf, Inf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optim.jl solver\n",
    "\n",
    "[List](https://docs.sciml.ai/Optimization/stable/optimization_packages/optim/) of algorithms in Optim.jl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using OptimizationOptimJL\n",
    "\n",
    "# BFGS algorithm (gradient based)\n",
    "sol = solve(prob, BFGS())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nelder-Mead algorithm (gradient free)\n",
    "sol = solve(prob, NelderMead())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjugate Gradient algorithm (gradient based)\n",
    "sol = solve(prob, ConjugateGradient())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLopt.jl solver\n",
    "\n",
    "[List](https://docs.sciml.ai/Optimization/stable/optimization_packages/nlopt/) of algorithms in OptimizationNLopt.jl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using OptimizationNLopt\n",
    "\n",
    "sol = solve(prob, NLopt.LD_LBFGS())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MathOptInterface.jl solver\n",
    "\n",
    "[List](https://docs.sciml.ai/Optimization/stable/optimization_packages/mathoptinterface/) of algorithms in OptimizationMOI.jl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using OptimizationMOI, Ipopt\n",
    "\n",
    "# Ipopt\n",
    "sol = solve(prob, Ipopt.Optimizer())"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "jupytext": {
   "formats": "ipynb,qmd"
  },
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "510.6000061035156px",
    "left": "0px",
    "right": "812px",
    "top": "109.4000015258789px",
    "width": "179.39999389648438px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
