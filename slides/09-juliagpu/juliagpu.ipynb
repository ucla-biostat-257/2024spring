{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: GPU Computing in Julia\n",
    "subtitle: Biostat/Biomath M257\n",
    "author: Dr. Hua Zhou @ UCLA\n",
    "date: today\n",
    "format:\n",
    "  html:\n",
    "    theme: cosmo\n",
    "    embed-resources: true\n",
    "    number-sections: true\n",
    "    toc: true\n",
    "    toc-depth: 4\n",
    "    toc-location: left\n",
    "    code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lecture introduces GPU computing in Julia.\n",
    "\n",
    "## GPGPU\n",
    "\n",
    "GPUs are ubiquitous in modern computers. Following are NVIDIA GPUs on today's typical computer systems.\n",
    "\n",
    "| NVIDIA GPUs         | H100 PCIe                           | RTX 6000                                 | RTX 5000                              |\n",
    "|---------------------|----------------------------------------|-----------------------------------------|--------------------------------------|\n",
    "|                     | ![H100](nvidia_h100.png) | ![RTX 6000](nvidia_rtx6000.png)    | ![RTX 5000](nvidia_rtx5000.png) |\n",
    "| Computers           | servers, cluster                       | desktop                                 | laptop                               |\n",
    "|                     | ![Server](gpu_server.jpg)       | ![Desktop](alienware-area51.png) | ![Laptop](macpro_inside.png)  |\n",
    "| Main usage          | scientific computing                   | daily work, gaming                      | daily work                           |\n",
    "| Memory              | 80 GB                                    | 48 GB                                   | 16 GB                                  |\n",
    "| Memory bandwidth    | 2 TB/sec                              | 960 GB/sec                               | 576 GB/sec                             |\n",
    "| Number of cores     | ???                                    | ???                                     | ???                                  |\n",
    "| Processor clock     | ??? GHz                                 | ??? GHz                                  | ??? GHz                               |\n",
    "| Peak DP performance | 26 TFLOPS                              | ??? TFLOPS                                        |                                    ??? TFLOPS  |\n",
    "| Peak SP performance | 51 TFLOPS                            | 91.1 TFLOPS                              | 42.6 TFLOPS                            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU architecture vs CPU architecture\n",
    "\n",
    "* GPUs contain 1000s of processing cores on a single card; several cards can fit in a desktop PC  \n",
    "\n",
    "* Each core carries out the same operations in parallel on different input data -- single program, multiple data (SPMD) paradigm  \n",
    "\n",
    "* Extremely high arithmetic intensity *if* one can transfer the data onto and results off of the processors quickly\n",
    "\n",
    "| ![i7 die](cpu_i7_die.png) | ![Fermi die](Fermi_Die.png) |\n",
    "|----------------------------------|------------------------------------|\n",
    "| ![Einstein](einstein.png) | ![Rain man](rainman.png)    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPGPU in Julia\n",
    "\n",
    "GPU support by Julia is under active development. Check [JuliaGPU](https://github.com/JuliaGPU) for currently available packages. \n",
    "\n",
    "There are multiple paradigms to program GPU in Julia, depending on the specific hardware.\n",
    "\n",
    "- **CUDA** is an ecosystem exclusively for Nvidia GPUs. There are extensive CUDA libraries for scientific computing: CuBLAS, CuRAND, CuSparse, CuSolve, CuDNN, ...\n",
    "\n",
    "  The [CUDA.jl](https://github.com/JuliaGPU/CUDA.jl) package allows defining arrays on **Nvidia GPUs** and overloads many common operations.\n",
    "\n",
    "- The [AMDGPU.jl](https://github.com/JuliaGPU/AMDGPU.jl) package allows defining arrays on **AMD GPUs** and overloads many common operations.\n",
    "\n",
    "- The [Metal.jl](https://github.com/JuliaGPU/Metal.jl) package allows defining arrays on **Apple Silicon** and overloads many common operations.\n",
    "\n",
    "- The [oneAPI.jl](https://github.com/JuliaGPU/oneAPI.jl) package allows defining arrays on **Intel GPUs** and overloads many common operations.\n",
    "\n",
    "I'll illustrate using Metal.jl on my MacBook Pro running MacOS Sonoma 14.4.1. It has Apple M2 chip with 38 GPU cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Pkg\n",
    "\n",
    "Pkg.activate(pwd())\n",
    "Pkg.instantiate()\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query GPU devices in the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Metal\n",
    "\n",
    "Metal.versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer data between main memory and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Random\n",
    "Random.seed!(257)\n",
    "\n",
    "# generate SP data on CPU\n",
    "x = rand(Float32, 3, 3)\n",
    "# transfer data form CPU to GPU\n",
    "xd = MtlArray(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate array on GPU directly\n",
    "# yd = Metal.ones(3, 3)\n",
    "yd = MtlArray(ones(Float32, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# collect data from GPU to CPU\n",
    "x = collect(xd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using BenchmarkTools, LinearAlgebra, Random\n",
    "\n",
    "Random.seed!(257)\n",
    "\n",
    "n = 2^14\n",
    "# on CPU\n",
    "x = rand(Float32, n, n)\n",
    "y = rand(Float32, n, n)\n",
    "z = zeros(Float32, n, n)\n",
    "# on GPU\n",
    "xd = MtlArray(x)\n",
    "yd = MtlArray(y)\n",
    "zd = MtlArray(z);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SP matrix dot product on GPU: tr(X'Y)\n",
    "# why are there allocations?\n",
    "bm_gpu = @benchmark Metal.@sync dot($xd, $yd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SP matrix dot product on CPU: tr(X'Y)\n",
    "bm_cpu = @benchmark dot($x, $y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# speedup\n",
    "median(bm_cpu.times) / median(bm_gpu.times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SP broadcast on GPU: z .= x .* y\n",
    "# why is there allocation?\n",
    "bm_gpu = @benchmark Metal.@sync $zd .= $xd .* $yd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SP broadcast on CPU: z .= x .* y\n",
    "bm_cpu = @benchmark $z .= $x .* $y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# speedup\n",
    "median(bm_cpu.times) / median(bm_gpu.times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SP matrix multiplication on GPU\n",
    "bm_gpu = @benchmark Metal.@sync mul!($zd, $xd, $yd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem size on this machine, we see GPU achieves a staggering **9 TFLOPS** throughput with single precision!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SP throughput on GPU\n",
    "(2n^3) / (minimum(bm_gpu.times) / 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SP matrix multiplication on CPU\n",
    "bm_cpu = @benchmark mul!($z, $x, $y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SP throughput on CPU\n",
    "(2n^3) / (minimum(bm_cpu.times) / 1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see >10x speedup by GPUs in this matrix multiplication example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cholesky on Gram matrix\n",
    "# This one doesn't seem to work on Apple M2 chip yet\n",
    "# xtxd = xd'xd + I\n",
    "# @benchmark Metal.@sync cholesky($(xtxd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtx = collect(xtxd)\n",
    "# @benchmark cholesky($(Symmetric(xtx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU speedup of Cholesky seems unavailable at the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of elementary and special functions on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# elementwise function on GPU arrays\n",
    "fill!(yd, 1)\n",
    "bm_gpu = @benchmark Metal.@sync $zd .= log.($yd .+ sin.($xd))\n",
    "bm_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# elementwise function on CPU arrays\n",
    "x, y, z = collect(xd), collect(yd), collect(zd)\n",
    "bm_cpu = @benchmark $z .= log.($y .+ sin.($x))\n",
    "bm_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Speed up\n",
    "median(bm_cpu.times) / median(bm_gpu.times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU brings great speedup (>50x) to the massive evaluation of elementary math functions."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "jupytext": {
   "formats": "ipynb,qmd"
  },
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
